# NISRA â€“ AI-Powered Mental Health Assistant

**A privacy-first, self-hostable mental health support system combining AI assistance with evidence-based wellness tools**
NISRA implements a **Hybrid Generative Adaptive RAG**, with local retrieval and API-based generation only. This ensures privacy-first, cost-efficient, and well-grounded responses.

---

## âš ï¸ Important Disclaimer

**NISRA is a research and educational prototype and is NOT a substitute for professional mental health care.** If you or someone you know is experiencing a mental health crisis, please contact:The required assistance 
---

## ğŸ“‹ Table of Contents

- [Overview](#-overview)
- [Features](#-features)
- [Technology Stack](#-technology-stack)
- [Installation](#-installation)
- [Configuration](#-configuration)
- [Usage](#-usage)
- [Project Structure](#-project-structure)
- [Limitations](#-limitations)
- [Authors](#-authors)

---

## ğŸ¯ Overview

NISRA (Neural Interactive Support & Resource Assistant) is a  mental health assistant demonstrating responsible AI implementation in sensitive domains which includes RAG. The system combines:

- **Local AI Model Processing**: Fine-tuned TinyLlama-1.1B with PEFT adapters and RAG responses
- **Multi-Modal Response System**: Local model, professional guidance, and web-assisted responses
- **Crisis Detection & Intervention**: Rule-based safety layer with emergency resources
- **Holistic Wellness Features**: Mood tracking, breathing exercises, games, and resources
- **RAG Based Response**:uses RAG based response and api-key for generation 
### Use Cases

- Academic research and demonstrations
- Educational AI/ML projects
- Privacy-focused mental health support prototyping

---

## âœ¨ Features

### ğŸ¤– AI-Powered Chat Interface

- **Multiple Response Modes**:
  - **Training Model**: Fine-tuned local model with mental health specialization
  - **Professional**: Safe, guidance-oriented responses by api key 
  - **RAG System**: Mental health knowledge base with hybrid FAISS + BM25 retrieval, cross-encoder re-ranking (ms-marco-MiniLM-L-6-v2), and adaptive web augmentation under low-confidence conditions (<0.6).
  - **Web-Assisted**: Context-enriched responses using web search
  - **Mixed Strategy**: Adaptive combination of available modes

- Intelligent conversation history management
- Real-time typing indicators
- User-configurable response strategy

### Technical Features

âš¡ Smart Caching:

- FAISS index cached after first build (~73 seconds startup)
- Subsequent loads: <2 seconds
- Response caching for frequently asked questions

## Models Used

- RAG Embeddings: all-mpnet-base-v2 (768 dimensions) - Best sentence transformer for semantic search
- Re-ranker: cross-encoder/ms-marco-MiniLM-L-6-v2 - Improves top-k results quality
- Fine-tuned Model: TinyLlama-1.1B-Chat with PEFT adapters
- Professional LLM: Llama 3.2 Vision via Ollama API (configurable)

## Multi-Format Data Support:

- CSV files (counsel_chat, mental_health_faq, crisis_support)
- JSON files (therapy_sessions, structured dialogues)

### ğŸ›¡ï¸ Safety & Crisis Management

- Keyword-based crisis detection for high-risk language patterns
- Immediate intervention with crisis-specific responses
- Emergency resource modal with helplines and professional resources
- Optional guardian alert system (SMS/email notifications)
- Multi-layer safety checks and content filtering

### ğŸ§˜ Wellness Companion Features

- **Mood Tracker**: Visual mood logging with analytics
- **Breathing Exercises**: Guided breathing patterns with audio
- **Physical Exercise Library**: 
  - Aerobic exercises with video demonstrations
  - Yoga poses with video guides
- **Games & Activities**: Relaxation-focused content
- **Resource Center**: Curated mental health resources
- **Ambient Soundscapes**: Nature sounds (rain, ocean, birds, waterfall)

### ğŸ‘¤ User Management

- Authentication system (signup, login, session management)
- Password recovery via email/SMS
- Local browser storage for privacy
- Customizable user preferences

---

## ğŸ›  Technology Stack

### Backend
- **Framework**: Flask 
- **ML/AI**: Hugging Face Transformers, PyTorch, PEFT
- **Model**: TinyLlama-1.1B-Chat-v1.0
- **Communication**: SMTP (email), Twilio (SMS)(optional)

### Frontend
- **Framework**: React with Vite
- **Styling**: Tailwind CSS
- **State Management**: Context API
- **Package Manager**: npm 11.6.2

### Infrastructure
- **Backend**: http://127.0.0.1:5000
- **Frontend**: http://localhost:3000
- **Model**: Local inference (self-hosted)

---

## ğŸ“¦ Installation

### Prerequisites

- **Python**: 3.10
- **Node.js**: 24.10.0
- **npm**: 11.6.2
- **Git**: For repository cloning

### training model 

## ğŸ§  Model Training (Required for Local AI Mode)

This project supports **local fine-tuned inference**.  
To enable the **Training Model** response mode, you must first fine-tune the base language model using the provided counseling dataset.

---

### ğŸ“‚ Dataset

- **Path**
  ```
  document_store/20200325_counsel_chat.csv
  ```
- **Source**: Counseling-style questionâ€“answer dataset  
- **Purpose**: Used to specialize the base LLM for mental healthâ€“oriented conversations

---

### ğŸ§ª Training Environment Options

You can train the model using either of the following environments:

- **Jupyter Notebook (Local Machine)**
- **Google Colab (Recommended â€“ GPU support)**

> âš ï¸ **CPU-based training is not recommended** due to high memory consumption and long training time.

---

## Download & Prepare RAG Data

1.**Download datasets from HuggingFace**
   - python download_datasets.py

2.**Build RAG index (runs automatically on first app.py launch)**
   -python rag_retriever.py


### ğŸš€ Training Steps (Google Colab â€“ Recommended)

1. **Open Google Colab**

2. Navigate to **Runtime â†’ Change runtime type**
   - **Hardware Accelerator**: `GPU`[used here is cpu for local deployment trained using gpu]
   - **Python version**: `3.10`

3. **Clone the repository**
   ```bash
   git clone https://github.com/Nischayss/mental_health.git
   cd mental_health_chatbot
   ```

4. **Install training dependencies**
   ```bash
   pip install -r requirements.txt
   ```

5. **Open the training notebook**
   ```
   trained_model/1_train_model.ipynb
   ```

6. **Update the dataset path inside the notebook**
   ```python
   DATASET_PATH = "document_store/20200325_counsel_chat.csv"
   ```

7. **Run all cells in the notebook**
   - Loads the base model (**TinyLlama-1.1B**)
   - Applies **LoRA / PEFT fine-tuning**
   - Trains on counseling conversations
   - Saves trained adapters automatically

---

### ğŸ“Œ Notes

- Model training is a **one-time process**
- Re-training is only required if:
  - The dataset is updated
  - The base model is changed
- Without training, the application will fall back to API-based or rule-based responses

### Backend Setup

```bash
# Clone the repository
git clone https://github.com/Nischayss/mental_health.git
cd mental_health_chatbot

# Create and activate virtual environment
python -m venv .venv

# Windows
.venv\Scripts\activate

# macOS/Linux
source .venv/bin/activate

# Install dependencies
pip install -r requirements.txt

# Configure environment variables
cp .env.example .env
# Edit .env with your settings

# Run backend
python app.py
```

**Backend runs at**: `http://127.0.0.1:5000`

### Frontend Setup

```bash
# Navigate to frontend
cd frontend

# Install dependencies
npm install

# Configure environment
cp .env.example .env
# Edit .env with your settings

# Start development server
npm start
```

**Frontend runs at**: `http://localhost:3000`

### Model Setup (Optional)

For local model inference:

1. Download TinyLlama-1.1B-Chat-v1.0 from Hugging Face
2. Place model files in `MODEL_BASE_PATH` directory
3. Ensure PEFT adapters are in `trained_model/` directory
4. Update `.env` with correct paths

> **Note**: Application works without local models using fallback responses or external APIs.

---

## âš™ï¸ Configuration

### Backend Environment Variables (`.env`)

```env
# Application Security
SECRET_KEY=your-secret-key-here

# Local Model Paths
MODEL_BASE_PATH=path/to/TinyLlama-1.1B-Chat-v1.0
ADAPTER_PATH=trained_model

# External LLM API (Optional)
LLM_API_URL=https://api.openai.com/v1/chat/completions
LLM_API_KEY=your-api-key-here

# Email Configuration (Optional)
SMTP_EMAIL=your-email@gmail.com
SMTP_APP_PASSWORD=your-app-password

# Twilio SMS (Optional)
TWILIO_ACCOUNT_SID=your-account-sid
TWILIO_AUTH_TOKEN=your-auth-token
TWILIO_PHONE_NUMBER=+1234567890

# Web Search (Optional)
SEARCH_API_KEY=your-search-api-key
```

### Frontend Environment Variables (`frontend/.env`)

```env
# API Endpoint
REACT_APP_API_URL=http://127.0.0.1:5000

# Feature Flags
REACT_APP_ENABLE_WEB_SEARCH=true
REACT_APP_ENABLE_CRISIS_ALERTS=true
```

### Security Notes

- Never commit `.env` files
- Use strong, unique `SECRET_KEY`
- Rotate API keys regularly
- Enable HTTPS in production

---

## ğŸš€ Usage

### Starting the Application

1. **Start Backend**:
   ```bash
   python app.py
   ```

2. **Start Frontend** (new terminal):
   ```bash
   cd frontend
   npm start
   ```

3. **Access**: Open browser to `http://localhost:3000`

### Basic Workflow

1. Create account or login
2. Select response mode (Training/Professional/Web/Mix)
3. Start conversation in chat interface
4. Explore wellness features from sidebar
5. Crisis support activates automatically when needed

### API Endpoints

#### Chat
```http
POST /chat
Content-Type: application/json

{
  "message": "I'm feeling anxious today",
  "mode": "professional",
  "user_id": "user123"
}
```

#### Health Check
```http
GET /health
```

#### Authentication
```http
POST /auth/signup
POST /auth/login
POST /auth/logout
POST /auth/reset-password
```

---

## ğŸ“ Project Structure

```
mental_health_chatbot/
â”œâ”€â”€ app.py                      # Flask application entry point
â”œâ”€â”€ rag_retriever.py            # RAG/FAISS retrieval logic
â”œâ”€â”€ requirements.txt            # Python dependencies
â”œâ”€â”€ .env.example                # Environment template
â”œâ”€â”€ .gitignore
â”‚
â”œâ”€â”€ templates/
â”‚   â””â”€â”€ index.html
â”‚
â”œâ”€â”€ trained_model/              # Model config & adapters
â”‚   â”œâ”€â”€ 1_train_model.ipynb
â”‚   â”œâ”€â”€ adapter_config.json
â”‚   â”œâ”€â”€ tokenizer files...
â”‚   â””â”€â”€ README.md
â”‚
â”œâ”€â”€ frontend/                   # React application
â”‚   â”œâ”€â”€ package.json
â”‚   â”œâ”€â”€ vite.config.js
â”‚   â”œâ”€â”€ tailwind.config.js
â”‚   â”‚
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ App.jsx
â”‚   â”‚   â”œâ”€â”€ main.jsx
â”‚   â”‚   â”œâ”€â”€ index.css
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ BreathingExercise.jsx
â”‚   â”‚   â”œâ”€â”€ Exercise.jsx
â”‚   â”‚   â”œâ”€â”€ GamesHub.jsx
â”‚   â”‚   â”œâ”€â”€ MoodTracker.jsx
â”‚   â”‚   â”œâ”€â”€ Resources.jsx
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ components/
â”‚   â”‚   â”‚   â”œâ”€â”€ Auth.jsx
â”‚   â”‚   â”‚   â”œâ”€â”€ CrisisModal.jsx
â”‚   â”‚   â”‚   â”œâ”€â”€ ModelSelector.jsx
â”‚   â”‚   â”‚   â”œâ”€â”€ chat/
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ ChatInput.jsx
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ ChatMessage.jsx
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ ChatWindow.jsx
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ FloatingChatButton.jsx
â”‚   â”‚   â”‚   â””â”€â”€ ui/
â”‚   â”‚   â”‚       â”œâ”€â”€ Button.jsx
â”‚   â”‚   â”‚       â””â”€â”€ Sidebar.jsx
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ context/
â”‚   â”‚   â”‚   â””â”€â”€ AuthContext.jsx
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ hooks/
â”‚   â”‚   â”‚   â”œâ”€â”€ useChat.js
â”‚   â”‚   â”‚   â””â”€â”€ useTheme.js
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”‚   â””â”€â”€ api.js
â”‚   â”‚   â”‚
â”‚   â”‚   â””â”€â”€ utils/
â”‚   â”‚       â””â”€â”€ constants.js
â”‚   â”‚
â”‚   â””â”€â”€ static/
â”‚       â”œâ”€â”€ sounds/             # Ambient audio files
â”‚       â”‚   â”œâ”€â”€ birds-in-cressent.mp3
â”‚       â”‚   â”œâ”€â”€ gentle-rain.mp3
â”‚       â”‚   â”œâ”€â”€ ocean-waves.mp3
â”‚       â”‚   â””â”€â”€ small-waterfall.mp3
â”‚       â”‚
â”‚       â””â”€â”€ videos/             # Exercise videos
â”‚           â”œâ”€â”€ aerobics/
â”‚           â”‚   â”œâ”€â”€ arm_circles.mp4
â”‚           â”‚   â”œâ”€â”€ high_knees.mp4
â”‚           â”‚   â”œâ”€â”€ jumping_jack.mp4
â”‚           â”‚   â”œâ”€â”€ quick_feet.mp4
â”‚           â”‚   â””â”€â”€ scissor_chops.mp4
â”‚           â””â”€â”€ yoga/
â”‚               â”œâ”€â”€ bridge_pose.mp4
â”‚               â”œâ”€â”€ childs_pose.mp4
â”‚               â”œâ”€â”€ cobra.mp4
â”‚               â”œâ”€â”€ downward_dog.mp4
â”‚               â””â”€â”€ extended_triangle.mp4
â”‚
â””â”€â”€ assets/
    â””â”€â”€ highlights.svg
```

---

## âš ï¸ Limitations

### Technical
- Crisis detection uses keyword matching (not ML-based)
- Local model requires significant disk space and compute
- Browser storage is not encrypted
- No automated testing suite
- Single-user focus (not multi-user ready)

### Clinical
- **Not a medical device**: No FDA approval or clinical validation
- **Not therapy**: Does not replace licensed professionals
- **Not diagnostic**: Cannot diagnose conditions
- **Limited crisis handling**: Basic resource provision only

---

## ğŸ¤ Contributing

Contributions welcome! Areas of interest:

- Enhanced crisis detection algorithms
- Improved model fine-tuning
- New wellness features
- Testing suite development
- Documentation improvements
- Accessibility enhancements

### Steps

1. Fork the repository
2. Create feature branch (`git checkout -b feature/name`)
3. Commit changes (`git commit -m 'Add feature'`)
4. Push to branch (`git push origin feature/name`)
5. Open Pull Request

---

## ğŸ‘¥ Authors

- **Nischay SS**
- **Shivashankar Naik**
- **Shivashankar Murthy**
- **Ullas**

---

## ğŸ“„ License

This project is licensed under the MIT License.

---

## ğŸ™ Acknowledgments

- Hugging Face for transformer models and PEFT
- TinyLlama team for the base model
- Mental health professionals for guidance
- Open source community

---


**If you're in crisis, please reach out to a professional immediately.**

**NISRA is for learning and exploration, not a replacement for human care.**

Made with â¤ï¸ for mental health awareness and responsible AI development by us - team NISRA â¤ï¸

